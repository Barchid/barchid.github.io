{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to my place! I am a 3rd year PhD Researcher in Computer Vision & AI at the University of Lille. My research focuses on neuromorphic engineering, spiking neural networks , energy-efficient AI, and event cameras. Apart from research, I am interested in data-centric practices. During my early career, I intend to bring the power of MLOps into Computer Vision. I also like web and game development so you may possibily see such subjects here.","title":"Welcome to my place!"},{"location":"#welcome-to-my-place","text":"I am a 3rd year PhD Researcher in Computer Vision & AI at the University of Lille. My research focuses on neuromorphic engineering, spiking neural networks , energy-efficient AI, and event cameras. Apart from research, I am interested in data-centric practices. During my early career, I intend to bring the power of MLOps into Computer Vision. I also like web and game development so you may possibily see such subjects here.","title":"Welcome to my place!"},{"location":"cv/","text":"Industry CV \u26a1 Summary of Qualifications Computer Vision researcher with 3 years of research experience in deep learning for object detection/tracking and 3D scene understanding. Former Lead Fullstack & DevOps/MLOps engineer for large-scale real-time applications. Experienced collaborator in interdisciplinary projects in robotics and neuromorphic engineering. Manager of 5 research projects in neuromorphic computing. \ud83d\udc54 Professional Experience 2020 - Present 2020 2018 - 2019 PhD Researcher in Bio-inspired Computer Vision \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 Designed innovative techniques for energy-efficient machine vision using event cameras and bio-inspired neural networks. Led 5 research projects and coordinated collaboration with 2 laboratories, resulting in 2 working applications and 2 ongoing projects for 2023. Published 4 scientific articles as first author. Computer Vision Engineer for Autonomous Navigation \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 Successfully developed a semantic segmentation algorithm using RGB-D and 3D cameras for autonomous navigation. Collaborated with a research team in robotics to fit their needs. Lead Fullstack & DevOps Engineer \u2013 Hootside \ud83c\uddeb\ud83c\uddf7 Developed, deployed, and maintained the back-end for a real-time mobile application that uses intensive geolocation data. Led the backend development in the IT department. Elaborated efficient CI/CD practices to improve the code base. \ud83c\udf93 Education PhD, Neuromorphic Computer Vision \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 ( 2020 \u2013 2023 ) Master\u2019s degree, Computer Vision (\u2b50 Valedictorian) \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 ( 2018 \u2013 2020 ) Bachelor\u2019s degree, Fullstack Engineering (\u2b50 Valedictorian) \u2013 Institut Paul Lambin \ud83c\udde7\ud83c\uddea ( 2015 \u2013 2018 ) \u2699\ufe0f Technical Skills Deep Learning: PyTorch, Tensorflow, Keras, Lightning (Python) Data Engineering: Scikit-Learn, Numpy, Pandas, Jupyter, Metabase Computer Vision: OpenCV, Event Cameras (DVS), RGB-D & 3D Camera, CVAT, Tonic DevOps/MLOps: Docker, Kubernetes, Airflow, Gitlab CI/CD, Linux Fullstack Engineering: SQL, ASP.Net Core, PHP Symfony, Vue.js, Angular, ... Management: AGILE project management \u2795 Extra \ud83c\udfae Hobbies: Game & Web development, Cycling, Fantasy/Sci-fi literature, video games \ud83e\udd47 Awards: PhD Entrepreneurship Prize (University of Lille), Student Code Challenge 2019 Gold (SkillValue)","title":"Industry CV"},{"location":"cv/#industry-cv","text":"","title":"Industry CV"},{"location":"cv/#summary-of-qualifications","text":"Computer Vision researcher with 3 years of research experience in deep learning for object detection/tracking and 3D scene understanding. Former Lead Fullstack & DevOps/MLOps engineer for large-scale real-time applications. Experienced collaborator in interdisciplinary projects in robotics and neuromorphic engineering. Manager of 5 research projects in neuromorphic computing.","title":"\u26a1 Summary of Qualifications"},{"location":"cv/#professional-experience","text":"2020 - Present 2020 2018 - 2019 PhD Researcher in Bio-inspired Computer Vision \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 Designed innovative techniques for energy-efficient machine vision using event cameras and bio-inspired neural networks. Led 5 research projects and coordinated collaboration with 2 laboratories, resulting in 2 working applications and 2 ongoing projects for 2023. Published 4 scientific articles as first author. Computer Vision Engineer for Autonomous Navigation \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 Successfully developed a semantic segmentation algorithm using RGB-D and 3D cameras for autonomous navigation. Collaborated with a research team in robotics to fit their needs. Lead Fullstack & DevOps Engineer \u2013 Hootside \ud83c\uddeb\ud83c\uddf7 Developed, deployed, and maintained the back-end for a real-time mobile application that uses intensive geolocation data. Led the backend development in the IT department. Elaborated efficient CI/CD practices to improve the code base.","title":"\ud83d\udc54 Professional Experience"},{"location":"cv/#education","text":"PhD, Neuromorphic Computer Vision \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 ( 2020 \u2013 2023 ) Master\u2019s degree, Computer Vision (\u2b50 Valedictorian) \u2013 University of Lille \ud83c\uddeb\ud83c\uddf7 ( 2018 \u2013 2020 ) Bachelor\u2019s degree, Fullstack Engineering (\u2b50 Valedictorian) \u2013 Institut Paul Lambin \ud83c\udde7\ud83c\uddea ( 2015 \u2013 2018 )","title":"\ud83c\udf93 Education"},{"location":"cv/#technical-skills","text":"Deep Learning: PyTorch, Tensorflow, Keras, Lightning (Python) Data Engineering: Scikit-Learn, Numpy, Pandas, Jupyter, Metabase Computer Vision: OpenCV, Event Cameras (DVS), RGB-D & 3D Camera, CVAT, Tonic DevOps/MLOps: Docker, Kubernetes, Airflow, Gitlab CI/CD, Linux Fullstack Engineering: SQL, ASP.Net Core, PHP Symfony, Vue.js, Angular, ... Management: AGILE project management","title":"\u2699\ufe0f Technical Skills"},{"location":"cv/#extra","text":"\ud83c\udfae Hobbies: Game & Web development, Cycling, Fantasy/Sci-fi literature, video games \ud83e\udd47 Awards: PhD Entrepreneurship Prize (University of Lille), Student Code Challenge 2019 Gold (SkillValue)","title":"\u2795 Extra"},{"location":"publications/","text":"Publications 2022 Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras Barchid, Sami, Jos\u00e9 Mennesson, and Chaabane Dj\u00e9raba. \"Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras.\" arXiv preprint arXiv:2202.13662 (2022). Abstract: This paper presents \"Bina-Rep\", a simple representation method that converts asynchronous streams of events from event cameras to a sequence of sparse and expressive event frames. By representing multiple binary event images as a single frame of -bit numbers, our method is able to obtain sparser and more expressive event frames thanks to the retained information about event orders in the original stream. Coupled with our proposed model based on a convolutional neural network, the reported results achieve state-of-the-art performance and repeatedly outperforms other common event representation methods. Our approach also shows competitive robustness against common image corruptions, compared to other representation techniques. Bibtex @article{barchid2022bina, title={Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Dj{\\'e}raba, Chaabane}, journal={arXiv preprint arXiv:2202.13662}, year={2022} } Spiking Neural Networks for Frame-based and Event-based Single Object Localization Barchid, Sami, et al. \"Spiking Neural Networks for Frame-based and Event-based Single Object Localization.\" arXiv preprint arXiv:2206.06506 (2022). Abstract: Spiking neural networks have shown much promise as an energy-efficient alternative to artificial neural networks. However, understanding the impacts of sensor noises and input encodings on the network activity and performance remains difficult with common neuromorphic vision baselines like classification. Therefore, we propose a spiking neural network approach for single object localization trained using surrogate gradient descent, for frame- and event-based sensors. We compare our method with similar artificial neural networks and show that our model has competitive/better performance in accuracy, robustness against various corruptions, and has lower energy consumption. Moreover, we study the impact of neural coding schemes for static images in accuracy, robustness, and energy efficiency. Our observations differ importantly from previous studies on bio-plausible learning rules, which helps in the design of surrogate gradient trained architectures, and offers insight to design priorities in future neuromorphic technologies in terms of noise characteristics and data encoding methods. Bibtex @article{barchid2022spiking, title={Spiking Neural Networks for Frame-based and Event-based Single Object Localization}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Eshraghian, Jason and Dj{\\'e}raba, Chaabane and Bennamoun, Mohammed}, journal={arXiv preprint arXiv:2206.06506}, year={2022} } 2021 Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning Barchid, Sami, Jos\u00e9 Mennesson, and Chaabane Dj\u00e9raba. \"Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning.\" 2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021. Abstract: With the advent of neuromorphic hardware, spiking neural networks can be a good energy-efficient alternative to artificial neural networks. However, the use of spiking neural networks to perform computer vision tasks remains limited, mainly focusing on simple tasks such as digit recognition. It remains hard to deal with more complex tasks (e.g. segmentation, object detection) due to the small number of works on deep spiking neural networks for these tasks. The objective of this paper is to make the first step towards modern computer vision with supervised spiking neural networks. We propose a deep convolutional spiking neural network for the localization of a single object in a grayscale image. We propose a network based on DECOLLE, a spiking model that enables local surrogate gradient-based learning. The encouraging results reported on Oxford-IIIT-Pet validates the exploitation of spiking neural networks with a supervised learning approach for more elaborate vision tasks in the future. Bibtex @inproceedings{barchid2021deep, title={Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Dj{\\'e}raba, Chaabane}, booktitle={2021 International Conference on Content-Based Multimedia Indexing (CBMI)}, pages={1--5}, year={2021}, organization={IEEE} } Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks Barchid, Sami, Jos\u00e9 Mennesson, and Chaabane Dj\u00e9raba. \"Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks.\" 2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021. Bibtex @inproceedings{barchid2021review, title={Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Dj{\\'e}raba, Chaabane}, booktitle={2021 International Conference on Content-Based Multimedia Indexing (CBMI)}, pages={1--4}, year={2021}, organization={IEEE} } Abstract: Many research works focus on leveraging the complementary geometric information of indoor depth sensors in vision tasks performed by deep convolutional neural networks, notably semantic segmentation. These works deal with a specific vision task known as \"RGB-D Indoor Semantic Segmentation\". The challenges and resulting solutions of this task differ from its standard RGB counterpart. This results in a new active research topic. The objective of this paper is to introduce the field of Deep Convolutional Neural Networks for RGB-D Indoor Semantic Segmentation. This review presents the most popular public datasets, proposes a categorization of the strategies employed by recent contributions, evaluates the performance of the current state-of-the-art, and discusses the remaining challenges and promising directions for future works.","title":"Publications"},{"location":"publications/#publications","text":"","title":"Publications"},{"location":"publications/#2022","text":"","title":"2022"},{"location":"publications/#bina-rep-event-frames-a-simple-and-effective-representation-for-event-based-cameras","text":"Barchid, Sami, Jos\u00e9 Mennesson, and Chaabane Dj\u00e9raba. \"Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras.\" arXiv preprint arXiv:2202.13662 (2022). Abstract: This paper presents \"Bina-Rep\", a simple representation method that converts asynchronous streams of events from event cameras to a sequence of sparse and expressive event frames. By representing multiple binary event images as a single frame of -bit numbers, our method is able to obtain sparser and more expressive event frames thanks to the retained information about event orders in the original stream. Coupled with our proposed model based on a convolutional neural network, the reported results achieve state-of-the-art performance and repeatedly outperforms other common event representation methods. Our approach also shows competitive robustness against common image corruptions, compared to other representation techniques. Bibtex @article{barchid2022bina, title={Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Dj{\\'e}raba, Chaabane}, journal={arXiv preprint arXiv:2202.13662}, year={2022} }","title":"Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras"},{"location":"publications/#spiking-neural-networks-for-frame-based-and-event-based-single-object-localization","text":"Barchid, Sami, et al. \"Spiking Neural Networks for Frame-based and Event-based Single Object Localization.\" arXiv preprint arXiv:2206.06506 (2022). Abstract: Spiking neural networks have shown much promise as an energy-efficient alternative to artificial neural networks. However, understanding the impacts of sensor noises and input encodings on the network activity and performance remains difficult with common neuromorphic vision baselines like classification. Therefore, we propose a spiking neural network approach for single object localization trained using surrogate gradient descent, for frame- and event-based sensors. We compare our method with similar artificial neural networks and show that our model has competitive/better performance in accuracy, robustness against various corruptions, and has lower energy consumption. Moreover, we study the impact of neural coding schemes for static images in accuracy, robustness, and energy efficiency. Our observations differ importantly from previous studies on bio-plausible learning rules, which helps in the design of surrogate gradient trained architectures, and offers insight to design priorities in future neuromorphic technologies in terms of noise characteristics and data encoding methods. Bibtex @article{barchid2022spiking, title={Spiking Neural Networks for Frame-based and Event-based Single Object Localization}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Eshraghian, Jason and Dj{\\'e}raba, Chaabane and Bennamoun, Mohammed}, journal={arXiv preprint arXiv:2206.06506}, year={2022} }","title":"Spiking Neural Networks for Frame-based and Event-based Single Object Localization"},{"location":"publications/#2021","text":"","title":"2021"},{"location":"publications/#deep-spiking-convolutional-neural-network-for-single-object-localization-based-on-deep-continuous-local-learning","text":"Barchid, Sami, Jos\u00e9 Mennesson, and Chaabane Dj\u00e9raba. \"Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning.\" 2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021. Abstract: With the advent of neuromorphic hardware, spiking neural networks can be a good energy-efficient alternative to artificial neural networks. However, the use of spiking neural networks to perform computer vision tasks remains limited, mainly focusing on simple tasks such as digit recognition. It remains hard to deal with more complex tasks (e.g. segmentation, object detection) due to the small number of works on deep spiking neural networks for these tasks. The objective of this paper is to make the first step towards modern computer vision with supervised spiking neural networks. We propose a deep convolutional spiking neural network for the localization of a single object in a grayscale image. We propose a network based on DECOLLE, a spiking model that enables local surrogate gradient-based learning. The encouraging results reported on Oxford-IIIT-Pet validates the exploitation of spiking neural networks with a supervised learning approach for more elaborate vision tasks in the future. Bibtex @inproceedings{barchid2021deep, title={Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Dj{\\'e}raba, Chaabane}, booktitle={2021 International Conference on Content-Based Multimedia Indexing (CBMI)}, pages={1--5}, year={2021}, organization={IEEE} }","title":"Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning"},{"location":"publications/#review-on-indoor-rgb-d-semantic-segmentation-with-deep-convolutional-neural-networks","text":"Barchid, Sami, Jos\u00e9 Mennesson, and Chaabane Dj\u00e9raba. \"Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks.\" 2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021. Bibtex @inproceedings{barchid2021review, title={Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks}, author={Barchid, Sami and Mennesson, Jos{\\'e} and Dj{\\'e}raba, Chaabane}, booktitle={2021 International Conference on Content-Based Multimedia Indexing (CBMI)}, pages={1--4}, year={2021}, organization={IEEE} } Abstract: Many research works focus on leveraging the complementary geometric information of indoor depth sensors in vision tasks performed by deep convolutional neural networks, notably semantic segmentation. These works deal with a specific vision task known as \"RGB-D Indoor Semantic Segmentation\". The challenges and resulting solutions of this task differ from its standard RGB counterpart. This results in a new active research topic. The objective of this paper is to introduce the field of Deep Convolutional Neural Networks for RGB-D Indoor Semantic Segmentation. This review presents the most popular public datasets, proposes a categorization of the strategies employed by recent contributions, evaluates the performance of the current state-of-the-art, and discusses the remaining challenges and promising directions for future works.","title":"Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks"}]}