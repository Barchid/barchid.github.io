
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.0, mkdocs-material-8.5.6">
    
    
      
        <title>Publications - Sami Barchid</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.20d9efc8.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Montserrat";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="youtube" data-md-color-primary="#d35400" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#publications" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Sami Barchid" class="md-header__button md-logo" aria-label="Sami Barchid" data-md-component="logo">
      
  <img src="../coffee.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sami Barchid
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Publications
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Sami Barchid" class="md-nav__button md-logo" aria-label="Sami Barchid" data-md-component="logo">
      
  <img src="../coffee.svg" alt="logo">

    </a>
    Sami Barchid
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Welcome to my place!
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../cv/" class="md-nav__link">
        Industry CV
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Publications
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Publications
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#2022" class="md-nav__link">
    2022
  </a>
  
    <nav class="md-nav" aria-label="2022">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bina-rep-event-frames-a-simple-and-effective-representation-for-event-based-cameras" class="md-nav__link">
    Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spiking-neural-networks-for-frame-based-and-event-based-single-object-localization" class="md-nav__link">
    Spiking Neural Networks for Frame-based and Event-based Single Object Localization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2021" class="md-nav__link">
    2021
  </a>
  
    <nav class="md-nav" aria-label="2021">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deep-spiking-convolutional-neural-network-for-single-object-localization-based-on-deep-continuous-local-learning" class="md-nav__link">
    Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#review-on-indoor-rgb-d-semantic-segmentation-with-deep-convolutional-neural-networks" class="md-nav__link">
    Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#2022" class="md-nav__link">
    2022
  </a>
  
    <nav class="md-nav" aria-label="2022">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bina-rep-event-frames-a-simple-and-effective-representation-for-event-based-cameras" class="md-nav__link">
    Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spiking-neural-networks-for-frame-based-and-event-based-single-object-localization" class="md-nav__link">
    Spiking Neural Networks for Frame-based and Event-based Single Object Localization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2021" class="md-nav__link">
    2021
  </a>
  
    <nav class="md-nav" aria-label="2021">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deep-spiking-convolutional-neural-network-for-single-object-localization-based-on-deep-continuous-local-learning" class="md-nav__link">
    Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#review-on-indoor-rgb-d-semantic-segmentation-with-deep-convolutional-neural-networks" class="md-nav__link">
    Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="publications">Publications</h1>
<h2 id="2022">2022</h2>
<h3 id="bina-rep-event-frames-a-simple-and-effective-representation-for-event-based-cameras">Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras</h3>
<p>Barchid, Sami, José Mennesson, and Chaabane Djéraba. "Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras." arXiv preprint arXiv:2202.13662 (2022). </p>
<p><strong>Abstract:</strong> This paper presents "Bina-Rep", a simple representation method that converts asynchronous streams of events from event cameras to a sequence of sparse and expressive event frames. By representing multiple binary event images as a single frame of -bit numbers, our method is able to obtain sparser and more expressive event frames thanks to the retained information about event orders in the original stream. Coupled with our proposed model based on a convolutional neural network, the reported results achieve state-of-the-art performance and repeatedly outperforms other common event representation methods. Our approach also shows competitive robustness against common image corruptions, compared to other representation techniques.</p>
<div class="highlight"><span class="filename">Bibtex</span><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>@article{barchid2022bina,
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>  title={Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras},
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>  author={Barchid, Sami and Mennesson, Jos{\&#39;e} and Dj{\&#39;e}raba, Chaabane},
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>  journal={arXiv preprint arXiv:2202.13662},
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>  year={2022}
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>}
</code></pre></div>
<p><br/></p>
<h3 id="spiking-neural-networks-for-frame-based-and-event-based-single-object-localization">Spiking Neural Networks for Frame-based and Event-based Single Object Localization</h3>
<p>Barchid, Sami, et al. "Spiking Neural Networks for Frame-based and Event-based Single Object Localization." arXiv preprint arXiv:2206.06506 (2022).</p>
<p><strong>Abstract:</strong> Spiking neural networks have shown much promise as an energy-efficient alternative to artificial neural networks. However, understanding the impacts of sensor noises and input encodings on the network activity and performance remains difficult with common neuromorphic vision baselines like classification. Therefore, we propose a spiking neural network approach for single object localization trained using surrogate gradient descent, for frame- and event-based sensors. We compare our method with similar artificial neural networks and show that our model has competitive/better performance in accuracy, robustness against various corruptions, and has lower energy consumption. Moreover, we study the impact of neural coding schemes for static images in accuracy, robustness, and energy efficiency. Our observations differ importantly from previous studies on bio-plausible learning rules, which helps in the design of surrogate gradient trained architectures, and offers insight to design priorities in future neuromorphic technologies in terms of noise characteristics and data encoding methods.</p>
<div class="highlight"><span class="filename">Bibtex</span><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>@article{barchid2022spiking,
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>  title={Spiking Neural Networks for Frame-based and Event-based Single Object Localization},
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>  author={Barchid, Sami and Mennesson, Jos{\&#39;e} and Eshraghian, Jason and Dj{\&#39;e}raba, Chaabane and Bennamoun, Mohammed},
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>  journal={arXiv preprint arXiv:2206.06506},
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>  year={2022}
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>}
</code></pre></div>
<p><br></p>
<h2 id="2021">2021</h2>
<h3 id="deep-spiking-convolutional-neural-network-for-single-object-localization-based-on-deep-continuous-local-learning">Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning</h3>
<p>Barchid, Sami, José Mennesson, and Chaabane Djéraba. "Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning." 2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</p>
<p><strong>Abstract:</strong> With the advent of neuromorphic hardware, spiking neural networks can be a good energy-efficient alternative to artificial neural networks. However, the use of spiking neural networks to perform computer vision tasks remains limited, mainly focusing on simple tasks such as digit recognition. It
remains hard to deal with more complex tasks (e.g. segmentation, object detection) due to the small number of works on deep spiking neural networks for these tasks. The objective of this paper is to make the first step towards modern computer vision with supervised spiking neural networks. We propose a deep
convolutional spiking neural network for the localization of a single object in a grayscale image. We propose a network based on DECOLLE, a spiking model that enables local surrogate gradient-based learning. The encouraging results reported on Oxford-IIIT-Pet validates the exploitation of spiking neural networks with a supervised learning approach for more elaborate vision tasks in the future.</p>
<div class="highlight"><span class="filename">Bibtex</span><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>@inproceedings{barchid2021deep,
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>  title={Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning},
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>  author={Barchid, Sami and Mennesson, Jos{\&#39;e} and Dj{\&#39;e}raba, Chaabane},
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>  booktitle={2021 International Conference on Content-Based Multimedia Indexing (CBMI)},
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>  pages={1--5},
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>  year={2021},
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>  organization={IEEE}
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>}
</code></pre></div>
<p><br/></p>
<h3 id="review-on-indoor-rgb-d-semantic-segmentation-with-deep-convolutional-neural-networks">Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks</h3>
<p>Barchid, Sami, José Mennesson, and Chaabane Djéraba. "Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks." 2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</p>
<div class="highlight"><span class="filename">Bibtex</span><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>@inproceedings{barchid2021review,
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>  title={Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks},
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>  author={Barchid, Sami and Mennesson, Jos{\&#39;e} and Dj{\&#39;e}raba, Chaabane},
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>  booktitle={2021 International Conference on Content-Based Multimedia Indexing (CBMI)},
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>  pages={1--4},
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>  year={2021},
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>  organization={IEEE}
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>}
</code></pre></div>
<p><strong>Abstract:</strong> Many research works focus on leveraging the complementary geometric information of indoor depth sensors in vision tasks performed by deep convolutional neural networks, notably semantic segmentation. These works deal with a specific vision task known as "RGB-D Indoor Semantic Segmentation". The challenges and resulting solutions of this task differ from its standard RGB counterpart. This results in a new active research topic. The objective of this paper is to introduce the field of Deep Convolutional Neural Networks for RGB-D Indoor Semantic Segmentation. This review presents the most popular public datasets, proposes a categorization of the strategies employed by recent contributions, evaluates the performance of the current state-of-the-art, and discusses the remaining challenges and promising directions for future works.</p>
<p><br/></p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../cv/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Industry CV" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Industry CV
            </div>
          </div>
        </a>
      
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/BarchidSami" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.linkedin.com/in/sami-barchid/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://github.com/Barchid" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.078830c0.min.js"></script>
      
    
  </body>
</html>